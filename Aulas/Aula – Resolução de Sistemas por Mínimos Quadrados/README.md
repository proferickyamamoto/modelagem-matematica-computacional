# Aula â€“ ResoluÃ§Ã£o de Sistemas por MÃ­nimos Quadrados

## ğŸ¯ Objetivos
- Entender quando um sistema **nÃ£o possui soluÃ§Ã£o exata** e como encontrar a **melhor aproximaÃ§Ã£o**.  
- Aplicar o **mÃ©todo dos MÃ­nimos Quadrados** em sistemas sobredeterminados (m > n).  
- Implementar a soluÃ§Ã£o em **Python**, **Octave** ou **R**.  
- Analisar a geometria e o significado da projeÃ§Ã£o em subespaÃ§os.

---

## ğŸ§  IntroduÃ§Ã£o

Nem todo sistema linear tem soluÃ§Ã£o exata.

Exemplo:  
\$$
A x = b, \quad A \in \mathbb{R}^{m \times n}, \; m > n
\$$

Quando **m > n**, temos **mais equaÃ§Ãµes do que incÃ³gnitas**.  
Normalmente **nÃ£o existe x** tal que \(A x = b\).  
Mas podemos buscar **xÌ‚** que **minimiza o erro** \(||A x - b||_2\).

ğŸ‘‰ Essa Ã© a ideia do **mÃ©todo dos MÃ­nimos Quadrados**.

---

## ğŸ“‰ Conceito GeomÃ©trico

- O vetor \(A xÌ‚\) Ã© a **projeÃ§Ã£o ortogonal** de \(b\) sobre o espaÃ§o coluna de \(A\).  
- O resÃ­duo \(r = b - A xÌ‚\) Ã© **ortogonal** a todas as colunas de \(A\).

Logo:
\[
A^T (b - A xÌ‚) = 0
\]
\[
\Rightarrow A^T A xÌ‚ = A^T b
\]

ğŸ“˜ Esta equaÃ§Ã£o Ã© chamada de **EquaÃ§Ã£o Normal**.

---

## ğŸ§® Exemplo NumÃ©rico

Sistema sobredeterminado:

\[
A =
\begin{bmatrix}
1 & 1 \\
1 & 2 \\
1 & 3
\end{bmatrix},
\quad
b =
\begin{bmatrix}
1 \\ 2 \\ 2
\end{bmatrix}
\]

**Etapas:**
1ï¸âƒ£ Calcular \(A^T A\) e \(A^T b\)
\[
A^T A =
\begin{bmatrix}
3 & 6 \\
6 & 14
\end{bmatrix},
\quad
A^T b =
\begin{bmatrix}
5 \\ 11
\end{bmatrix}
\]

2ï¸âƒ£ Resolver:
\[
(A^T A) xÌ‚ = A^T b
\Rightarrow
\begin{bmatrix}
3 & 6 \\
6 & 14
\end{bmatrix}
\begin{bmatrix}
a \\ b
\end{bmatrix}
=
\begin{bmatrix}
5 \\ 11
\end{bmatrix}
\]

3ï¸âƒ£ SoluÃ§Ã£o:
\[
xÌ‚ =
\begin{bmatrix}
a \\ b
\end{bmatrix}
=
(A^T A)^{-1} A^T b
=
\begin{bmatrix}
0.333 \\ 0.667
\end{bmatrix}
\]

âœ… Resultado:
\[
\hat{y} = 0.333 + 0.667 x
\]

---

## ğŸ“ˆ InterpretaÃ§Ã£o

O vetor \(xÌ‚\) representa os **coeficientes da reta de regressÃ£o** que melhor ajusta os pontos:
(1,1), (2,2), (3,2)

GrÃ¡fico:  
ğŸ“‰ A reta nÃ£o passa exatamente pelos pontos, mas **minimiza o erro total quadrÃ¡tico**.

---

## ğŸ’» ImplementaÃ§Ã£o em Python

```python
import numpy as np

A = np.array([[1,1],
              [1,2],
              [1,3]], dtype=float)
b = np.array([[1],[2],[2]], dtype=float)

# MÃ©todo dos mÃ­nimos quadrados
x_hat = np.linalg.inv(A.T @ A) @ A.T @ b
print("SoluÃ§Ã£o por mÃ­nimos quadrados:\n", x_hat)

# VerificaÃ§Ã£o via funÃ§Ã£o pronta
x_np, _, _, _ = np.linalg.lstsq(A, b, rcond=None)
print("SoluÃ§Ã£o com lstsq():\n", x_np)
````

---

## ğŸ’» ImplementaÃ§Ã£o em Octave

```octave
A = [1 1; 1 2; 1 3];
b = [1; 2; 2];

x_hat = inv(A'*A) * A' * b
x_oct = A \ b   % mÃ©todo embutido (usa QR)
```

---

## ğŸ’» ImplementaÃ§Ã£o em R

```r
A <- matrix(c(1,1, 1,2, 1,3), ncol=2, byrow=TRUE)
b <- c(1,2,2)

x_hat <- solve(t(A) %*% A) %*% t(A) %*% b
x_lm <- lm(b ~ A[,2])
x_hat
summary(x_lm)
```

---

## ğŸ“Š Comparativo com LU e QR

| MÃ©todo            | Tipo de sistema  | Estabilidade  | Custo computacional |
| :---------------- | :--------------- | :------------ | :------------------ |
| LU                | Quadrado         | Boa           | O(nÂ³)               |
| QR                | Retangular (mâ‰¥n) | **Melhor**    | O(mnÂ²)              |
| MÃ­nimos Quadrados | Sobredeterminado | Boa           | O(mnÂ²)              |
| SVD               | Qualquer         | **Excelente** | O(mnÂ² + nÂ³)         |

---

## ğŸ§¾ ExercÃ­cios em Sala

1ï¸âƒ£ Resolva por mÃ­nimos quadrados:
[
A =
\begin{bmatrix}
1 & 1 \
1 & 2 \
1 & 4
\end{bmatrix},
\quad
b =
\begin{bmatrix}
2 \ 3 \ 6
\end{bmatrix}
]

2ï¸âƒ£ Compare os resultados de (xÌ‚) com o mÃ©todo direto `np.linalg.lstsq(A,b)`.

3ï¸âƒ£ Plote o grÃ¡fico (pontos e reta ajustada).

4ï¸âƒ£ Teste um caso com ruÃ­do:
b = [1.2, 1.9, 3.1]
Como o resultado muda?

---

## ğŸ  Tarefa (para casa)

* Explique, com suas palavras, o significado de **projeÃ§Ã£o ortogonal**.
* Gere um exemplo em que o sistema seja **superdeterminado (m>n)** e outro **subdeterminado (m<n)**, e descreva as diferenÃ§as.
* Entregue um pequeno **relatÃ³rio (PDF)** com:

  * cÃ³digos usados,
  * grÃ¡ficos,
  * e anÃ¡lise em 1 parÃ¡grafo.

---

## ğŸ“š ReferÃªncias

* Strang, G. *Introduction to Linear Algebra*.
* Trefethen & Bau, *Numerical Linear Algebra*.
* Lay, D. *Linear Algebra and Its Applications*.
* MIT OCW â€“ *18.06 Linear Algebra*, Lecture 23: Least Squares Problems.

---

ğŸš€ **ConclusÃ£o:**
O mÃ©todo dos **MÃ­nimos Quadrados** fornece uma soluÃ§Ã£o aproximada para sistemas sem soluÃ§Ã£o exata, minimizando o erro entre os dados e o modelo linear â€” base essencial para **regressÃ£o**, **ajuste de curvas** e **aprendizado de mÃ¡quina**.

